# faceSelectiveNeuronExperiment

This notebook, faceSelectiveNeuronsExperiment.ipynb, implements a set of experiments designed to identify and analyze face-selective neurons within a deep neural network that models human visual processing. The primary goal is to determine which neurons in the network respond most strongly to face stimuli and to quantify their selectivity across various categories. The script utilizes pre-trained models and a biologically inspired framework (TopoNets) to simulate hierarchical neural responses to visual input. Key functionalities include computing neuron activations across image datasets, determining selectivity indices, and visualizing the most strongly activating stimuli for selected neurons. This analysis is crucial for bridging the gap between artificial neural networks and biological vision systems, particularly in understanding how representations of socially and biologically relevant stimuli like faces emerge in neural topographies. By identifying and studying face-selective units, the experiment contributes to both neuroscience and machine learning by improving the interpretability of models and offering insight into the neural coding strategies underlying face perception.
